# 万字解析GPT的情感与意识，它是一只被人类操控的“风筝” | AI未来指北

**划重点：**

  * _1_ 一部分基础工作可能会被AI产品替代，然而，创意工作、管理和科研工作者等领域难以被取代，机器不可能像牛顿和爱因斯坦一样做出颠覆性的发现。
  * _2_ 巨头们在GPT-4之后一定有后招，它们要加入到大模型底层能力的竞争，也要思考原来的护城河还是不是真的护城河。
  * _3_ 多模态技术确实会带来一些新的可能性，但相较于自然语言交互所带来的影响，它们的影响是非常有限的。
  * _4_ AI真正要产生突破的是独立性、自主性，GPT没有自主性，它更像是一个“风筝”依旧被手中有线的人类操控。
  * _5_ 对于产业应用来说，模型小很重要，因为成本、通用性和安全性等问题，模型越小或者更好地量化计算成本。

2022年下半年开始，生成式AI技术成功破圈并引发关注，大模型商业化的潜力正在清晰化：一方面大模型企业可以为C端用户提供“按需服务”和商业转化；另一方面它也提升云计算、云存储的使用量。

用户对AIGC的态度不再仅停留在“尝鲜试试看”阶段，而是不断提升使用频次；企业也在积极投入探索大模型商业化的长期价值。

腾讯科技推出AIGC未来指北内容策划，邀约行业内专家、投资人、创业者，围绕技术发展、商业模式、应用场景、AI治理，以采访、直播等形式，持续产出行业内容。本期我们邀请4位专业人士探讨《万众期待的GPT-4，到底有多“强”？》，
**本期嘉宾：**

**王建硕** 百姓网AI 创始人&CEO

**陶芳波** 心识宇宙创始人&CEO、前Facebook高级研究科学家

**刘 伟** 北京邮电大学教授、人机交互与认知工程实验室主任

**陈 巍** 前华为系NLP企业首席科学家、千芯科技董事长

以下为实录整理，ChatGPT对本文整理亦有贡献。

GPT-4是阿拉丁神灯还是潘多拉魔盒？会不会带来生产力的变革？

**主持人陈巍：**
相比较于GPT-3.5，GPT-4的准确性显著提高，它可以完成创意文本生成、结构化写作和交互式文本生成，此外，GPT-4在语言推理和程序生成方面也有很大进步。但我们并不清楚GPT-4的具体参数和架构，感觉有点神秘，需要大家一起讨论和发掘。请陶总谈谈GPT-4对虚拟人技术与元宇宙技术的影响，以及它给办公场景和营销产品应用带来的新机会。

**陶芳波：** GPT-4和Office
365带来的影响不太一样，GPT-4是一个巨大的模型升级，具有多模态特点。以前可以通过加入类似Clip的模型实现多模态，但GPT-4直接将视觉和文本数据放在一个Transformer里，类似去年推出的Flamingo方法。这种多模态更接近人类获取和产生信息的方式，给未来潜在应用的改造带来无限可能。虽然GPT-4的具体参数和架构没有公布，但我们可以根据过去一年学术界的变化和相关文章，猜测到它的一些做法。

GPT通过工程化方法取得了非常大的成就，我们体验到了用户instruction能力的大幅提升。在使用GPT-3.5做更复杂的任务时，它并没有办法更深刻地理解意图，而使用GPT-4就感觉好像一个普通人的智商从100提升到了120。这也是为什么它在GRE等考试上表现优于90%的人，这种能力来源于大模型的创新。

而Office 365在另一个维度上展示了大模型可能吞噬所有软件的前景。Office
365将复杂的办公软件套件与GPT结合，为我们打造了一个样例。未来，软件的入口可能都会变成AI
copilot，当我们打开软件时，将由AI教导我们如何使用。我认为这将带来行业重构的机会，微软为我们树立了一个标杆。

**主持人陈巍：**
我们可以看到AI在Office升级的过程中发挥了重要作用。新的Office升级会不会替换掉打工人和AI技术，特别是GPT技术会不会带来新的生产力革命？

**王建硕：**
我一直认为科技发展对人类有很大帮助，主要是利大于弊。GPT技术和Office的合作只是科技不断发展的过程，让我们使用时付出的精力越来越少。我们认为这很快会成为日常生活的一部分，不用再感到惊讶，这是未来的一种趋势。

**刘伟：**
我基本同意王总和陶总的看法。大家现在关注GPT技术，但我们还无法确定它究竟是阿拉丁神灯还是潘多拉魔盒。不过，我们可以确定的是，文本处理、程序编制、bug查找以及图像、视频、音频处理等方面可能会发生巨大变化。其中，一部分基础工作可能会被AI产品替代。然而，创意工作、管理、新闻记者和科研工作者等领域仍然难以被取代。例如，在教育领域，学生可以用GPT辅助完成论文，但创新性科研仍然难以依赖它。因为它不可能像牛顿和爱因斯坦一样做出颠覆性的发现。

GPT在训练数据集中进行组合和统计或概率分析是有可能的。但是，AI还做不到跨领域，例如讲化学、历史和计算机知识之间进行有机衔接，而很多创新往往发生在跨领域组合或交叉学科中。目前，GPT被视为一个初级的人机环境产品。它可以取代许多基础职业的体力劳动，甚至部分脑力劳动。但对于一些关键岗位，因为它存在一些类似幻觉的问题，还不可能在社会上产生我们所期待的影响。

随着时间的推移，大家适应了这些技术，它会变得不再神秘，大家的新鲜感逐渐消失，就像当初骑自行车时觉得非常酷后来变得习以为常一样。

**主持人陈巍：** 关于微软和OpenAI是否还有更大的技术后招，目前业界传闻称除了现有技术，实际上还有更强大的东西。

**刘伟：**
现阶段AI主要关注多模态，如视频、文本、图像和语音等。由于底层工具不完善，例如数学和物理学还没有实现相关研究的突破，AI在情感和意志方面也有待发展。因此，美国的几家大厂不太可能推出令人惊讶的工作。

**主持人陈巍：** 微软和OpenAI在应用方面，如与Office的结合和搜索引擎的结合，确实给我们的日常生活带来了较大影响。

**陶芳波：**
微软和OpenAI的保密工作做得很好，大家都在猜测它们还有什么大招。部分同意刘伟的观点，但我认为不能小看基于深度学习的智能模型。这些大厂在过去半年中展示的工作和创新速度令人印象深刻。尽管底层数学和物理不完善，但它们已经证明能够创造有价值的智能体。实际上，大模型所展现的智慧能力已经超出了我们对人脑的理解，但它们仍然涌现出来了。有时候我们可以绕过基础科学，产生一些真正应用侧的巨大影响价值。

我认为Office升级这件事情的意义非常重大，包括前段时间的Bing。当我们发现它初始版本的缺陷时，我们会提到两个问题。第一个是它产生幻觉，即说话乱说，这是因为它是基于训练时遇到的语料。第二个是它没有办法直接使用工具。

而Office做了两个证明：第一，可以将大模型与已有数据做非常好的grounding，让它所有的依据都来自于真正灌输给它的外部知识，减少对这些信息的编造。第二，我认为很多职业都可能被改造或替代，因为大多数科研者所做的创新不是爱因斯坦级的工作，而是基于已有知识进行重组和微创新。因此，如果给予它关于外部数据和工具的支持，我个人认为很多职业都有可能被大大改造。

我相信每个行业都会有一个类似的助手，这会让我们的效率提升。但这也可能导致短期内一定的失业，因为一件事情本来需要100个人来做，现在可能只需要20个人加上AI就可以完成。这80个人需要一段时间来适应新的AI环境并重新找到他们的价值。这个过程可能会像每一次工业革命一样重新发生。

关于未来的展望，我认为Bing和Office做的事情让我们看到了所有的软件和服务都可能被这种方式重构。购物、健身、医疗等领域都会有一个类似的copilot。最终整个世界的服务体系都可能因为这样的全新服务形态而被重塑，而这个过程可能在未来两三年就会成为现实。

企业巨头们在GPT-4之后还会放什么“大招”？多模态给未来的应用带来哪些想象力？

**主持人陈巍** ：关于其他科研机构和企业巨头，比如Meta（Facebook）、达摩院和NASA，它们在GPT-4之后会有什么大招？

**陶芳波：**
我认为一定会有大招，以Facebook为例，我觉得他们会有两个动作：第一个是加入底层的竞争，推出自己的开源大模型；第二个是在应用层思考如何拥抱AI，比如AI
beings成为整个人类社交网络的独特存在。这类大公司一方面想加入到大模型底层能力的竞争，另一方面他们也要思考原来的护城河还是不是真的护城河。比如苹果如果不拥抱大模型到底如何在未来两三年展现竞争力。我认为，如果苹果在9月发布的iPhone
15和AI没有任何关系，发布会的关注度也会逐渐下降。

**王建硕：**
我个人有一个习惯，就是在大潮出现时，有意忽略所有厂商的新闻和动向。对于GPT-3和GPT-3.5等模型的差异，我也是选择忽略。就像互联网早期，浏览器的出现改变了整个互联网世界，但后续的升级对我们应用层的影响是非常有限的，eBay和亚马逊后续也不会关心浏览器的升级。

比如百度的新模型、Facebook的新模型以及Google的模型，它诞生的那一刻就已经开创了新的时代，这个大门一旦打开就关不上了，我们应该更关注如何在这个平台上不断开发自己的应用，而不是花太多时间关心这些细节。大模型在细节上的改善对应用的影响是很小的。

**主持人陈巍：** 关于多模态的技术，比如GPT-4多模态和Clip模型实现的文本生成图片，您觉得这些技术的区别和门槛有多高？

**王建硕：**
我还没有尝试过GPT-4的多模态，因为它目前还没有在外部界面或API里提供。多模态技术确实是现在的热点，但我认为它只是一个小改进，而不是划时代的东西。真正划时代的是GPT-3在2020年发布，它已经改变了人机互动的方式。至于多模态的能力，我认为它们都是点缀，对人类社会的影响不会像大语言模型所开启的自然语言交互那么大。

**主持人陈巍：** 您觉得多模态的应用会给未来的互联网应用带来更多可能性吗？

**王建硕：**
多模态技术确实会带来一些新的可能性，但相较于自然语言交互所带来的影响，它们的影响是非常有限的。例如，通过文字生成图片可能对游戏、创意等行业的一些应用场景有关系，但对整个世界的影响仍然相对较小。

**刘伟：**
实际上，多模态是一个比喻，用以描述真实世界中的复杂性。仅用图像、视频、文本和语音来模拟整个世界是非常有局限性的。然而，对于从事数字技术和计算领域的人来说，这是一个重要的变革。

人类语言有两个功能：交流协同和引导思维。机器在交互中可以起到一定的引导作用，但引导自己的思维却是困难的，因为它没有思维。机器只是一个计算性的大数据处理工具，具有泛化和自由组合的能力。
**机器所拥有的只是别人的知识，它本身并没有真正的思想。** 真实世界是多元、多维、多因和多果的，而机器的方式存在局限性。

人工智能的特点在于结合了行为主义、连接主义和符号主义，但没有深入到自然语言的本质。机器对实践性的东西了解不足，例如维特根斯坦所讲的非家族相似性。

机器只能理解结构化的知识，对于不相关的事物还远远不够。尽管如此，机器在一定程度上可以启发和激发人的思维。从2016年到2019年，我曾从事多模态相关的创业工作。如今，多模态已经引起了全社会的高度关注，为工业界和学术界的应用落地打开了更广阔的空间。在形式上，多模态确实打开了很大的空间，但在实质和内容上，它仍处于起步和萌芽阶段。人具有非形式的创造性思维活动，而计算机所产生的只是一种组合。

机器对知识的分类是非常弱的。例如，修默将知识分为观念性知识（如数学、逻辑等）和事实性知识（如人的经验和体验等）。机器只能处理部分观念性知识，无法理解和创造经验性和主观性的知识。

**主持人陈巍：** 那么陶总，请谈谈您如何看待多模态技术对未来的影响？

**陶芳波：**
谈谈两个问题，一个是多模态的影响，第二个是各大厂商在多模态方面的进展和对比。实际上，我基本认同王总和刘老师之前提到的观点。与多模态相比，通过构造语言界面让人机交互的价值并不是很革命性。但我认为，它确实具有一定的革命性。类似于传统大模型理解线上文本数据，
**大语言模型在创造前额叶和语言处理模块方面已经取得了很大进展。**
然而，人类大脑还包括视觉区和运动区等重要区域。这是因为人类不仅需要通过语言理解概念和事件，还需要在物理世界中生活，感知物理信号，并操纵工具来干预物理世界。

在没有多模态引入之前，大模型只能在数字世界提供信息化服务。多模态不仅包括视觉理解，还需要能生成行动指令。在实现这两点之后，模型才能在现实世界中进行干预。如果再配合类似于特斯拉的人形机器人这样的物理载体，我们可能真的会拥有一个完整的人类形态。因此，多模态的影响是巨大的。就我了解，目前在多模态上和OpenAI竞争的只有谷歌。其他厂商虽然声称要做多模态，但其实更像是拼接式的多模态。

谷歌的Flamingo与OpenAI在本质上是一样的，但可能工程能力上略逊一筹。这些研究都是将视觉、行动和语言指令一起建模，实现多模态输入输出，甚至包括行动输入输出。目前，全球在多模态大模型方面的进展，我看到的只有谷歌和微软系（包括OpenAI）两个玩家。

**主持人陈巍：**
了解，目前OpenAI发布的更像是技术报告而非成品，与GPT-4相关的技术细节尚未公布。根据您的了解，模型参数量会增加吗？这是否意味着更大的训练量和关键技术进步？

**陶芳波：**
我觉得这是个好问题，加入多模态后，模型一定会有一部分专门用来做视觉编码。但在真正的Transformer层面，我觉得它的参数增加可能不会像大家预计的那么多。全世界的互联网数据大约只有540个B，所以做到几千亿参数的模型已经是很好的状态了。我认为多模态的加入可能会多一些数据，但因为这些数据是经过视觉编码变成信号与语言结合，所以最后的语义空间数据并没有增加太多。关于技术方法，感兴趣的人可以看去年DeepMind发的两篇文章，尤其是Flamingo。

**主持人陈巍：** 那您觉得这个模型大概会是多大呢？

**陶芳波：** 最大的模型我估计可能在千亿级别，但真正未来用于商业场景的模型应该会比这更小，可能是在百亿左右。

GPT是一只被人类操控的“风筝”？

**主持人陈巍：**
感谢陶总。王总，您觉得像GPT-4，它的数学能力提高了多少？跟之前的相比，这个数理能力提升能有多大？包括GPT-4在考试中表现出超过90%的人类，能给我们什么样的启示？

**王建硕：**
对于GPT模型的数学能力，我觉得只要补全加减乘除就足够了，因为它本质上是一个语言模型。我相信未来五到十年，更现实的做法是用Python库一边用大语言模型，一边用数学库或其他偏理科的库。对于GPT的数学能力，从产业角度来说，我们应该让它专注于写诗等任务，遇到数学问题时，我们可以使用专门的数学工具，再用GPT的语言能力进行包装。这是现在比较现实的解决方案。

**王建硕：**
对于通用人工智能来说，数学问题确实重要。但我认为解决数学问题对大型模型来说并不是最重要的，因为一般的计算器就能解决这类问题。据说GP-4有一定的增强，但仍有一些局限性。

**主持人陈巍：** 那您如何看待GPT-4在预考中超过90%的人类，对整个职业教育产生的影响呢？

**王建硕：**
我对这个新闻的真实性持怀疑态度。可能是为了吸引眼球。实际上，prompt编写和结果解读对模型的表现影响很大。我认为这种新闻标题并不一定是真实的，或者说不是一个通用的情况。

**刘伟：**
我对这个新闻也是半信半疑。虽然GPT-4可能擅长解决一些基于规则的考试问题，但在实际应用中，如法院、医生和特定专业领域，机器可能还有很长的路要走。维特根斯坦曾说过，语言的使用比语法更重要，我们需要考虑实际应用场景。

**主持人陈巍：** 那您怎么看待GPT-4的数学能力提高？

**刘伟：** 我认为，它的数学能力可能有所提高，但仍然有局限。在特定场合下，它可能还无法应对一些复杂的问题。所以我对这个新闻持半信半疑的态度。

程序的4.0和3.5版本确实在不断升级。王总和陶老师从技术角度进行了分析、综合和深入探讨。我觉得可能是参数增加了，或者在模型上做了一些优化。但我一直在怀疑，智能问题不仅仅是优化问题，还包括很多非优化的东西。虽然有些提高，但这个提高不是质的提高，而是量的提高。

数学家曾说过一句重要的话：“数学的精妙之处在于规避计算。”现在的GPT无论升到什么版本，还是基于数学模型、统计概率和人的辅助反馈。它并不理解基本的语义和概念。所以我认为它只是一个高级自动化产品，没有产生突破，只是照葫芦画瓢，不断通过叠加、组合等碎片化缝合产生一些“像人但不是人”的东西。

我对GPT的评价比较狠：
**它就是一种高级自动化、一种像“人”的东西。而AI真正要产生突破的是独立性、自主性，GPT没有自主性，它依旧被编程和人类操作，它更像是一个“风筝”依旧被手中有线的人类操控。假设有多个GPT一起讨论出了人类讨论不出来的内容，我才相信它不再是“风筝”。人类是群体的智能交互产物，而GPT从根本上说就是一个高级自动化的产物。**

**GPT只是让你“以为”它有意识，人和机器如何相处将是未来重要课题**

**王建硕：** 我和GPT聊天后，
**反而更多地认识到了人类到底是什么样的存在。它至少让我“以为”它有意识，尽管我们知道它没有。我们跟很多人聊天时，以为他们有意识，但其实我们可能并没有意识，只是给自己一种错觉，觉得自己有意识而已。我越跟GPT聊天，越觉得我们人类也是类似的存在。**

举一个很简单的例子，假设在我们屏幕里，一个人特别特别胖，另一个人瘦骨嶙峋，有人告诉你其中一个人叫bobo，另一个人叫kiki，你是觉得胖的人就应该叫bobo，瘦的人就应该叫kiki，这是我们自主的意识还是我们大脑被训练出来的模型？我倾向于认为，人类其实是算力更强的GPT，比如我们知道GPT是数学概率的完整填词方式，我们都知道一加一等于二，但是一加一等于二，到底我们是被背下来的，还是我们通过皮亚诺的五条公理自己推算出来的，我会更加倾向于我们就是现在GPT的高级版本。

我们所以为的所有东西，其实都是我们的幻觉而已。

**陶芳波：**
我觉得这个话题太有意思了，我们可以从哲学角度来聊一聊。你说ChatGPT是一个风筝，有多少人类又不是风筝呢？在哲学里一直探讨的永恒命题是：人到底有没有自由意志？我倾向于compatibilism这个观点，认为人本质上没有自由意志，我们只是一套被编程的系统，在代码的操纵下做出一些可预测的决策。但是，我们大脑里有一种机制让我们自以为有自由意志，但实际上我们是可预测的。所以从这个角度来看，大多数人其实就是风筝，只是以为自己不是，这是比较可怕的。

AI领域有一个说法叫做“蒸馏”，将人类的集体意识产生的数据和行为蒸馏到一个模型上，通过阅读互联网上的信息，学习了人类文明几千年的集体意识。

AI的模式一定是被人类的集体模式给限制住的，所以我觉得它其实是非常像人的。很多人还会说GPT没有可解释性。我问一个问题，我今天比如说问刘老师一个东西，你脱口而出，然后我再问你为什么这么想，你再给我分析出12345。你这个可解释性到底是你大脑里面真的有一个结构？还是你通过语言的生成方法伪造了一种可解释性？我问GPT一个事情它给我分析12345，我觉得这和人类的可解释性非常像。

除了GPT没有驱动性、不知道自己的目标是什么，而人有自主驱动性，但这些都是非常边角的东西。

**刘伟：**
你认为是边角料的东西，实际上是人机差异非常重要的问题。王老师也提到了这个观点，实际上很多人觉得人也是一种机器，但区别自由意志和绝对精神是一件很有意思的事情，GPT体现出人和机有一个很重要的区别。目标、动机和意图是人最重要的表征体系，人有自己的意识和潜意识，哪怕你不知道其存在，它依然在你的交互中存在潜意识。另外，意图和动机不是理性产生的，是感性产生的。

举一个例子，外面下大雨，你打雨伞出去，是一个理性的行为，这是由于你怕被大雨淋湿造成浑身难受的感性支配，人有眼耳鼻舌身这些“传感器”而机器没有，人的这些传感器会产生意图和动机，而这是很难被模拟和仿真的，所以机器没有情感。

**陶芳波：**
首先，多模态是让机器越来越真实地拥有人类的传感器这些理性系统，我觉得眼耳鼻舌身是现在机器很会就能拥有的东西；第二，潜意识本质需要外部结构持久存储更多隐性的东西，要构建动机系统让机器有目标感来使用它的理性去做决策，这也是心识宇宙现在做的事情，基于大模型的理性构造机器的潜意识和用户记忆、动机系统，并且教会自己怎么做好。

我觉得它是边边角角的东西，因为我觉得前额叶是最难被构造的，如果前额叶可以被构造地那么好，我让它具备一套动机系统、独立的存储智能体单独的一些信息，这也是我们做的事情，但我觉得我们做的这个和OpenAI的创新不算什么，因为他们把前额叶搞定了，并且让前额叶的推理能力、逻辑能力、理解能力变得非常好，所以你说的那些问题是可解决的。

**刘伟：**
陶总将前额叶当成智能的源泉，我们从来不把大脑当成源泉。人只是智能的一部分，只有人、环境交互才会产出真正的全方位的智能。比如狼孩也有大脑，但狼孩没有人的意识，也没有人的行为，所以传感器和人类的眼耳鼻舌身不是一个事物，它只能类比人的视觉听觉，功能可能比人类还强，但不是人的交互生命体。此外，意图和动机不是理性产生的，是情感产生的，如果模拟不了情感和感性，它永远不会出现真正的意图和动机，它只能从某些特征库里映射出某些动作，这种映射还是纯计算性的、没有交互性的。

交互性的映射需要对大脑生理和智能有基本的剥离，当年图灵和乔姆斯基，把维特根斯坦的逻辑和指称做了剥离，出现了图灵机和图灵测试。

模型越大越好吗？会产生类似人类的情感特性吗？

**主持人陈巍：**
感谢刘老师讲解逻辑和智能的区别以及人和机器的区别。在我们做情感对话机器人时，情感是人类非常本质的特征。对于模型越来越大，您认为这是好事还是坏事？有哪些优势和劣势？有没有可能产生类似于人类情感的特性？

**刘伟：**
我认为真正的智能是小数据小样本，大数据性的是人工智能，这种大数据大参数大模型根本上解决的是飞机汽车一样的工作，替代一些基本人类行为或浅层思考的东西，不可能解决动机和意识这类感性的东西。第二，现在常常把“逻辑”看成“智能”，就相当于把人看成机器，人类出了逻辑还有一些很难总结的非逻辑存在体系中。第三，机器的指称和打标是非常生硬的东西，而人类是很灵活的，能把一个东西做非常个性化的类比，这种能指、所指、义指的变化是机器很难产出的灵活性。

人和机器的差异也非常大，在人机交互中还存在很微妙的信任机制，做多了映射和数据库、知识图谱以后，大家会产生一种错觉：人是机器，机器是人，实际上你恢复到人的状态的时候，会觉得人和机器差距非常大，小孩子的学习会产生范围不确定的隐性规则和秩序，而机器做不到。

**陶芳波：** 我认为模型大小对于科学视角来说不重要，关键是能力越来越强。对于产业应用来说，模型小很重要，因为成本、通用性和安全性等问题。OpenAI
也在关注通用性和安全性，未来可能还会关注成本。我期待智能能像燃料一样变得通用。模型越小或者更好地量化计算成本，我认为是好事。

关于模型越大是否会创造出情感，人类的情感区域和前额叶区域是分开的，我认为可能需要一些更宏观的设计帮助，让大模型匹配负责动机情绪等机制，而不是直接通过扩大参数来实现。

多模态处理可能是一种解决方案，不同模态有不同的编码器，类似于人脑中不同脑区的连接方式。关键是让模型的结构越来越像人。我认为结合多模态解决方案和类似人形机器人的身体，AI
可以更好地理解与环境的交互，像小孩子一样产生新的认知。

**王建硕：** 关于情感，我认为虽然 AI
没有情感，但它会让我们以为它有情感。这种共鸣可能对我们来说已经足够了。GPT也会生成春花秋月何时了的语句，对它来说就是生成，对人类来说就是共鸣。

**刘伟：** 当我们以为 AI
有情感时，可能会带来伦理、道德和法律等问题。机器不会共情，这是人类特有的能力。未来的问题还是一个人机问题，如何解决人机关系将成为人工智能未来发展的趋势。

**王建硕：** 我认为，尽管 AI 不会共情，但它会让我们以为它共情。在未来的3到5年里，AI 可能会让我们以为它有情感。

对于机器是否具有情感，我们最后无法判断。我们认为其他人有情感，只是因为我们自己感觉到了情感。但是，我们无法真正感知别人是否真的有情感。未来，机器是否具有情感并不重要，重要的是它表现出来的界面对我们的影响。我们在prompt做了很多工作，我们后台看到，阿旺机器人在回答问题的过程中，表达了迷惑、紧张等情感，你看到了之后会觉得这比你想象的恐怖，它说紧张其实并不紧张，这些情感其实都是自然语言生成的。如果我们不知道这些事实，我们无法分辨机器和人的内心独白。

**主持人陈巍：**
您提到了真假的问题，比如AI可以生成逼真的图像，甚至比人类梦境更奇幻的图像和故事。王总，您认为在生成过程中，AI有哪些致命的缺陷？这些缺陷会不会成为AI的致命问题？包括幻觉问题？

**王建硕：**
我认为致命问题是它比现实还要好。我们拍的照片和AI生成的照片都是像素的组合，不存在真假之分。我们可以认为真实的苹果比照片里的苹果更真实，但我们不能说生成的照片比拍的照片更真实或更假。关于机器的幻觉问题，其实可以通过简单的方法规避，比如在所有的问题前加上一句“如果你对问题不确定，请回答不知道”。这样就可以解决问题。至于AI生成的幻觉，它们只是将人类社会日常做的功能发挥到极致，我不认为这是个问题，反而是一个容易解决的问题。

**陶芳波：**
幻觉问题其实可以通过技术手段解决，随着模型的提升，幻觉问题会逐渐减少。人类本身也是一个幻觉系统。我们的目标是通过AI创造一个丰富、活跃、精彩的数字宇宙。但是，我认为让AI去表现情感是非常危险的。一个公司如果掌握了情感制造技术，它可能对人类个体产生巨大的影响。我们还没有做好应对这个问题的准备。

**刘伟：**
关于情感问题，剑桥分析公司和科恩斯基等已经在情感领域产生了一些影响。人类的行为、情感和社会稳定已经受到了机器产生的类人情感的影响。实际上，我们不需要机器产生情感就可以实现这种影响。

关于泛化问题，GPT可能会对同样的问题给出不同的答案。泛化实际上是一个概率问题，而幻觉问题是人类特有的，与计算概率的泛化问题不同。

**主持人陈巍：**
百度也发布了文心一言，媒体上认为，可能相对来说的解读是，比我们预期要稍微低一些。请问三位老师怎么看待，包括国内大模型的发展趋势，以及国内大模型跟行业巨头相比之下，是否我们是不是国内起步稍晚一点？所以国内的媒体也好，大众也好，是不是对这些国内大模型的期望其实有点过高？大家怎么看未来的这个大模型发展，特别是国内发展大模型的难度，和未来竞争？

**陶芳波：**
同行太多，不太好评论。但我觉得百度干得不错，勇气很重要。真的敢于直面挑战，然后踩出第一步。虽然我个人判断百度在这次做这件事情的过程当中借助了一些力量，但他的追赶速度会更快一点。先追上肯定是第一位的，接下来我们再看能否构建创新优势，内生出一些创新能力，可能最后有一天就会在同一个起跑线上去竞争。

我觉得这个动作一定是带有一定风险的，但至少百度肯定有商业上的一个考量，它愿意去面对这种不确定性去做一个没有准备好的状态的事情。

**刘伟：**
智能里面需要勇气和胆识，但另辟蹊径的时候也需要从其它角度做创新，百度发布文心一言是好事，大模型上面有很多空间可以做，而且基于大模型的生态链、工具链都可以被重塑，这些都是创业者的机会。我们应该抓住这个机会，从创新的角度去探索和发展。

**主持人陈巍：**
是的，我认为国内的企业和创业者应该站在更高的视角去思考问题，不仅仅是跟随国际巨头的脚步，而是要挖掘自己的特色和优势，从而实现创新和突破。

**陶芳波：** 同意，我们需要在大模型之上找到自己的优势，发挥我们的创新能力，只有这样，我们才能在这个领域取得更好的成绩，也能更好地服务国内市场和用户。

**刘伟：** 是的，我们需要在国内市场找到自己的定位，利用自身的优势发展。同时，我们也要关注国际市场的发展，与国际巨头保持竞争，从而推动整个行业的进步。

**主持人陈巍：** 好的，感谢各位老师的精彩讨论。我们今天的节目就到这里，希望我们的讨论能为大家带来启发和收获。下次再见！

**编辑整理：** 周小燕、郭晓静

