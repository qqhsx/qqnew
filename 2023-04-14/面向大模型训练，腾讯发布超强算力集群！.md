# 面向大模型训练，腾讯发布超强算力集群！

![](https://inews.gtimg.com/newsapp_match/0/15124755731/0)
请看标题。

这个国内超强算力集群，就是腾讯云新发布的 **面向大模型训练的新一代HCC** （High-Performance Computing Cluster）
**高性能计算集群，整体性能比过去提升了3倍。**

它搭载了 **NVIDIA H800 Tensor Core GPU** ，能够提供高性能、高带宽、低延迟的智算能力支撑。

当前大热的人工智能大模型训练，离不开高性能的算力集群。我们很高兴第一时间跟你分享这个好消息。

![](https://inews.gtimg.com/newsapp_bt/0/15776921121/1000)
一般运算，由运算卡（芯片）来完成。

但遇到海量运算，单块芯片无力支撑，就要将成千上万台服务器，通过网络联结，组成大型的算力集群，同心合力，更高更强。

一个人工智能大模型，通常得用数万亿个单词训练，参数量也“飙升”到了上万亿。这个时候，只有高性能的计算集群能hold住。

![](https://inews.gtimg.com/newsapp_bt/0/15776921124/1000)
算力集群的“强”，由单机算力、网络、存储共同决定。就像一个牢固的木桶，缺一不可。

腾讯云新一代集群通过对 **单机算力** 、 **网络架构** 和 **存储性能**
进行协同优化，能够为大模型训练提供高性能、高带宽、低延迟的智算能力支撑。

总体来说，有以下几个特点：

**计算方面，性能强——**

在单点算力性能最大优化的基础上，我们还将不同种类的芯片组合起来，GPU+CPU，让每块芯片去最恰当的地方，做最擅长的事情。

**网络方面，带宽足——**

GPU擅长并行计算，一次可以做多个任务。我们的 **自研星脉高性能网络**
，让成千上万的GPU之间互相“通气”，信息传递又快又不堵车，打一场漂亮的配合战，大模型集群训练效率提升了20%。

**存储方面，读取快——**

训练大模型时，几千台服务器会同时读取一批数据集，如果加载时间过长，也会成为木桶的短板。我们的最新自研存储架构，将数据分类放进不同“容器”，用作不同的场景，读取更快更高效。

![](https://inews.gtimg.com/newsapp_bt/0/15776921168/1000)
随着算力需求的陡增，自己采购GPU的价格昂贵，甚至有钱也买不到，给创业企业、中小企业带来很大压力。
**我们的新一代HCC集群，能够帮助在云上训练大模型，希望缓解他们的压力。**

我们有 **训练框架AngelPTM**
，对内支持了腾讯混元大模型的训练，也已通过腾讯云对外提供服务。它在去年10月，完成了首个万亿参数大模型训练，并将训练时间缩短80%。

我们的 **TI平台（一站式机器学习平台）** 拥有大模型能力和工具箱，能帮助企业根据具体场景，进行精调训练，提升生产效率，快速创建和部署 AI 应用。

我们的自研芯片已经量产，包括用于 **AI推理的紫霄芯片** 。它采用自研存算架构和自研加速模块，可以提供高达3倍的计算加速性能和超过45%的整体成本节省。

总体而言，我们正以新一代HCC为标志，基于自研芯片、自研服务器等方式，软硬一体，打造面向AIGC的高性能智算网络，持续加速全社会云上创新。

未来你希望算力来做什么？我们留言区见。

